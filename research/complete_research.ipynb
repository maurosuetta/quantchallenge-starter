{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae3969c",
   "metadata": {},
   "source": [
    "# Statistical Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d036aa8",
   "metadata": {},
   "source": [
    "### 1) Download libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "265c357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.iforest import IForest\n",
    "from tsfresh.feature_extraction import extract_features, EfficientFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh import extract_features\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b90b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_root(start: Path | None = None) -> Path:\n",
    "    p = (start or Path.cwd()).resolve()\n",
    "    for candidate in [p, *p.parents]:\n",
    "        if (candidate / \"pyproject.toml\").exists():\n",
    "            return candidate\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a241998",
   "metadata": {},
   "source": [
    "### 2) Download train data \n",
    "\n",
    "We first make data usable by downloading it into a Polars dataframeº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "01e8df09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA\n",
      "\n",
      "shape: (80_000, 19)\n",
      "┌───────┬───────────┬───────────┬───────────┬───┬──────┬──────┬───────────┬───────────┐\n",
      "│ time  ┆ A         ┆ B         ┆ C         ┆ … ┆ O    ┆ P    ┆ Y1        ┆ Y2        │\n",
      "│ ---   ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---  ┆ ---  ┆ ---       ┆ ---       │\n",
      "│ i64   ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64  ┆ f64  ┆ f64       ┆ f64       │\n",
      "╞═══════╪═══════════╪═══════════╪═══════════╪═══╪══════╪══════╪═══════════╪═══════════╡\n",
      "│ 0     ┆ 0.207366  ┆ -0.159951 ┆ -0.634176 ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.935902 ┆ -0.310081 │\n",
      "│ 1     ┆ 0.188828  ┆ -0.265508 ┆ 0.042143  ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.089707 ┆ -0.305374 │\n",
      "│ 2     ┆ -0.144261 ┆ -0.577142 ┆ -0.214634 ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.077855 ┆ -0.631485 │\n",
      "│ 3     ┆ 0.208982  ┆ -0.310449 ┆ 0.513708  ┆ … ┆ -1.0 ┆ 0.0  ┆ 0.941271  ┆ -0.535212 │\n",
      "│ 4     ┆ 0.09332   ┆ -0.358156 ┆ 0.173188  ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.039582 ┆ -0.490561 │\n",
      "│ …     ┆ …         ┆ …         ┆ …         ┆ … ┆ …    ┆ …    ┆ …         ┆ …         │\n",
      "│ 80000 ┆ -0.339802 ┆ -0.372094 ┆ -0.120952 ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.564065 ┆ -0.154864 │\n",
      "│ 80001 ┆ -0.421921 ┆ -0.222554 ┆ -0.689585 ┆ … ┆ -1.0 ┆ 0.0  ┆ 0.031323  ┆ -0.474736 │\n",
      "│ 80002 ┆ -0.467038 ┆ -0.282018 ┆ 0.010707  ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.213572 ┆ -0.503083 │\n",
      "│ 80003 ┆ -0.36971  ┆ -0.322384 ┆ -0.540326 ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.600713 ┆ -0.233209 │\n",
      "│ 80004 ┆ -0.304899 ┆ -0.047375 ┆ -0.932102 ┆ … ┆ 3.0  ┆ -1.0 ┆ -0.51891  ┆ -0.110204 │\n",
      "└───────┴───────────┴───────────┴───────────┴───┴──────┴──────┴───────────┴───────────┘\n",
      "TRAIN DATA\n",
      "\n",
      "shape: (5, 19)\n",
      "┌──────┬───────────┬───────────┬───────────┬───┬──────┬──────┬───────────┬───────────┐\n",
      "│ time ┆ A         ┆ B         ┆ C         ┆ … ┆ O    ┆ P    ┆ Y1        ┆ Y2        │\n",
      "│ ---  ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---  ┆ ---  ┆ ---       ┆ ---       │\n",
      "│ i64  ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64  ┆ f64  ┆ f64       ┆ f64       │\n",
      "╞══════╪═══════════╪═══════════╪═══════════╪═══╪══════╪══════╪═══════════╪═══════════╡\n",
      "│ 0    ┆ 0.207366  ┆ -0.159951 ┆ -0.634176 ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.935902 ┆ -0.310081 │\n",
      "│ 1    ┆ 0.188828  ┆ -0.265508 ┆ 0.042143  ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.089707 ┆ -0.305374 │\n",
      "│ 2    ┆ -0.144261 ┆ -0.577142 ┆ -0.214634 ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.077855 ┆ -0.631485 │\n",
      "│ 3    ┆ 0.208982  ┆ -0.310449 ┆ 0.513708  ┆ … ┆ -1.0 ┆ 0.0  ┆ 0.941271  ┆ -0.535212 │\n",
      "│ 4    ┆ 0.09332   ┆ -0.358156 ┆ 0.173188  ┆ … ┆ -1.0 ┆ -1.0 ┆ -0.039582 ┆ -0.490561 │\n",
      "└──────┴───────────┴───────────┴───────────┴───┴──────┴──────┴───────────┴───────────┘\n",
      "TEST DATA\n",
      "\n",
      "shape: (5, 16)\n",
      "┌─────┬───────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ id  ┆ time  ┆ A         ┆ B         ┆ … ┆ K         ┆ L         ┆ M         ┆ N         │\n",
      "│ --- ┆ ---   ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ i64 ┆ i64   ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
      "╞═════╪═══════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 1   ┆ 80005 ┆ -0.371888 ┆ -0.273485 ┆ … ┆ -0.3699   ┆ -0.378902 ┆ 0.470166  ┆ 0.411796  │\n",
      "│ 2   ┆ 80006 ┆ -0.459598 ┆ -0.514915 ┆ … ┆ -0.461901 ┆ -0.249516 ┆ -0.216745 ┆ -0.328599 │\n",
      "│ 3   ┆ 80007 ┆ -0.381609 ┆ -0.265023 ┆ … ┆ -0.272153 ┆ -0.193158 ┆ -0.679351 ┆ -0.476331 │\n",
      "│ 4   ┆ 80008 ┆ -0.371423 ┆ -0.106279 ┆ … ┆ 0.518678  ┆ -0.028775 ┆ -0.61062  ┆ -0.846772 │\n",
      "│ 5   ┆ 80009 ┆ -0.309393 ┆ -0.015144 ┆ … ┆ 0.185197  ┆ -0.150254 ┆ -1.08019  ┆ -0.685936 │\n",
      "└─────┴───────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "root_path = project_root()\n",
    "# 160,000 rows error fix \n",
    "train_data_1 = pd.read_csv(root_path / \"data\" / \"train.csv\")\n",
    "train_data_2 = pd.read_csv(root_path / \"data\" / \"train_new.csv\") # in windows, use \"\\\"\n",
    "\n",
    "merged_data = pd.concat([train_data_1, train_data_2], axis=1)\n",
    "columns = [col for col in merged_data.columns if col not in ['Y1', 'Y2']] + ['Y1', 'Y2']\n",
    "merged_data = merged_data[columns]\n",
    "train_data = pl.DataFrame(merged_data).with_columns(pl.col(\"time\").cast(int)).fill_null(-1)\n",
    "merged_data = merged_data.set_index(\"time\")\n",
    "merged_data.to_csv(root_path / \"data\" / \"full_train_data.csv\")\n",
    "print(\"TRAIN DATA\\n\")\n",
    "print(train_data)\n",
    "print(\"TRAIN DATA\\n\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"TEST DATA\\n\")\n",
    "test_data = pl.read_csv(root_path / \"data\" / \"test.csv\")\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a1e87",
   "metadata": {},
   "source": [
    "### 3) Visualize Relationship betweeen Targets and Explanatory Variables\n",
    "\n",
    "Plot features dependency with the variables into scatter plot grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f86639ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_vs_target(target: np.ndarray, label: str, num_rows: int, num_cols: int, columns_to_plot: List[str], colour: str):\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 5 * num_rows))\n",
    "    axes = np.atleast_1d(axes).ravel()\n",
    "    corr_dict = {}\n",
    "    y = np.asarray(target, dtype=float)\n",
    "\n",
    "    for i, col in enumerate(columns_to_plot):\n",
    "        ax = axes[i]\n",
    "        x = np.asarray(train_data[col], dtype=float)\n",
    "\n",
    "        m = np.isfinite(x) & np.isfinite(y)\n",
    "        corr = np.corrcoef(x[m], y[m])[0, 1] if m.any() else np.nan\n",
    "\n",
    "        corr_dict[col] = corr\n",
    "\n",
    "        ax.scatter(x[m], y[m], alpha=0.5, color=colour)\n",
    "        ax.set_title(f\"{col} vs {label}\\ncorr={corr:.4f}\" if np.isfinite(corr) else f\"{col} vs {label}\\ncorr=nan\")\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(label)\n",
    "\n",
    "    for j in range(len(columns_to_plot), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.suptitle(f\"Features vs {label}\", y=0.995, fontsize=16)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return corr_dict\n",
    "    \n",
    "\n",
    "def superpose_grids(targets: List[np.ndarray], labels: List[str], num_rows: int, num_cols: int, columns_to_plot: List[str], colours: List[str]):\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 5 * num_rows))\n",
    "    axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "    for i, col in enumerate(columns_to_plot):\n",
    "        ax = axes[i]\n",
    "        x = np.asarray(train_data[col].to_numpy(), dtype=float).ravel()\n",
    "        corrs = [] \n",
    "\n",
    "        for num, target in enumerate(targets):\n",
    "            y = np.asarray(target, dtype=float).ravel()\n",
    "            m = np.isfinite(x) & np.isfinite(y)\n",
    "            if m.sum() >= 2 and np.std(x[m]) > 0 and np.std(y[m]) > 0:\n",
    "                c = np.corrcoef(x[m], y[m])[0, 1]\n",
    "            else:\n",
    "                c = np.nan\n",
    "\n",
    "            corrs.append(c)\n",
    "            ax.scatter(x[m], y[m], alpha=0.5, label=labels[num], color=colours[num])\n",
    "    \n",
    "\n",
    "        corr_txt = \"  |  \".join(\n",
    "            f\"corr({lbl})={c:.4f}\" if np.isfinite(c) else f\"corr({lbl})=nan\"\n",
    "            for lbl, c in zip(labels, corrs)\n",
    "        )\n",
    "        ax.set_title(f\"{col} vs targets\\n{corr_txt}\")\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(\"target\")\n",
    "        ax.legend(loc=\"best\")\n",
    "\n",
    "    for j in range(len(columns_to_plot), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = [c for c in columns if c not in ['time', 'Y1', 'Y2']]\n",
    "num_cols = 4\n",
    "num_rows = -(-len(columns_to_plot) // num_cols)\n",
    "list_targets = [train_data[\"Y1\"].to_numpy(),train_data[\"Y2\"].to_numpy()]\n",
    "\n",
    "correlation_dict_Y1 = plot_grid_vs_target(list_targets[0], \"Y1\", num_rows, num_cols, columns_to_plot, \"blue\")\n",
    "print(\"\\n\")\n",
    "correlation_dict_Y2 = plot_grid_vs_target(list_targets[1], \"Y2\", num_rows, num_cols, columns_to_plot, \"red\")\n",
    "print(\"\\n\")\n",
    "superpose_grids(list_targets, [\"Y1\",\"Y2\"], num_rows, num_cols, columns_to_plot, [\"blue\",\"red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06f421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top by both (L2):\n",
      "\n",
      "shape: (16, 8)\n",
      "┌─────────┬───────────────┬──────────────┬──────────┬──────────┬──────────┬───────────┬────────────┐\n",
      "│ feature ┆ Correlation   ┆ Correlation  ┆ abs_Y1   ┆ abs_Y2   ┆ score_l2 ┆ score_max ┆ score_mean │\n",
      "│ ---     ┆ Y1            ┆ Y2           ┆ ---      ┆ ---      ┆ ---      ┆ ---       ┆ ---        │\n",
      "│ str     ┆ ---           ┆ ---          ┆ f64      ┆ f64      ┆ f64      ┆ f64       ┆ f64        │\n",
      "│         ┆ f64           ┆ f64          ┆          ┆          ┆          ┆           ┆            │\n",
      "╞═════════╪═══════════════╪══════════════╪══════════╪══════════╪══════════╪═══════════╪════════════╡\n",
      "│ G       ┆ 0.814568      ┆ -0.060187    ┆ 0.814568 ┆ 0.060187 ┆ 0.816788 ┆ 0.814568  ┆ 0.437377   │\n",
      "│ J       ┆ 0.723921      ┆ -0.097986    ┆ 0.723921 ┆ 0.097986 ┆ 0.730522 ┆ 0.723921  ┆ 0.410953   │\n",
      "│ H       ┆ 0.70756       ┆ -0.086976    ┆ 0.70756  ┆ 0.086976 ┆ 0.712885 ┆ 0.70756   ┆ 0.397268   │\n",
      "│ C       ┆ 0.703823      ┆ -0.073009    ┆ 0.703823 ┆ 0.073009 ┆ 0.707599 ┆ 0.703823  ┆ 0.388416   │\n",
      "│ M       ┆ 0.686246      ┆ -0.095326    ┆ 0.686246 ┆ 0.095326 ┆ 0.692835 ┆ 0.686246  ┆ 0.390786   │\n",
      "│ …       ┆ …             ┆ …            ┆ …        ┆ …        ┆ …        ┆ …         ┆ …          │\n",
      "│ L       ┆ -0.072366     ┆ 0.503546     ┆ 0.072366 ┆ 0.503546 ┆ 0.50872  ┆ 0.503546  ┆ 0.287956   │\n",
      "│ F       ┆ -0.073191     ┆ 0.496667     ┆ 0.073191 ┆ 0.496667 ┆ 0.502031 ┆ 0.496667  ┆ 0.284929   │\n",
      "│ A       ┆ -0.006105     ┆ 0.484746     ┆ 0.006105 ┆ 0.484746 ┆ 0.484785 ┆ 0.484746  ┆ 0.245426   │\n",
      "│ O       ┆ 0.177676      ┆ 0.167684     ┆ 0.177676 ┆ 0.167684 ┆ 0.244309 ┆ 0.177676  ┆ 0.17268    │\n",
      "│ P       ┆ 0.074776      ┆ 0.069005     ┆ 0.074776 ┆ 0.069005 ┆ 0.101751 ┆ 0.074776  ┆ 0.071891   │\n",
      "└─────────┴───────────────┴──────────────┴──────────┴──────────┴──────────┴───────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "correlation_df = pd.DataFrame({\n",
    "    'Correlation Y1': pd.Series(correlation_dict_Y1, dtype=float),\n",
    "    'Correlation Y2': pd.Series(correlation_dict_Y2, dtype=float),\n",
    "})\n",
    "correlation_df = correlation_df.fillna(0.0)\n",
    "\n",
    "correlation_df['abs_Y1'] = correlation_df['Correlation Y1'].abs()\n",
    "correlation_df['abs_Y2'] = correlation_df['Correlation Y2'].abs()\n",
    "\n",
    "correlation_df['score_l2'] = np.hypot(\n",
    "    correlation_df['Correlation Y1'],\n",
    "    correlation_df['Correlation Y2']\n",
    ")\n",
    "\n",
    "correlation_df['score_max'] = correlation_df[['abs_Y1', 'abs_Y2']].max(axis=1)\n",
    "correlation_df['score_mean'] = correlation_df[['abs_Y1', 'abs_Y2']].mean(axis=1)\n",
    "\n",
    "top_by_Y1 = correlation_df.sort_values('abs_Y1', ascending=False)\n",
    "\n",
    "top_by_Y2 = correlation_df.sort_values('abs_Y2', ascending=False)\n",
    "\n",
    "top_by_both = correlation_df.sort_values('score_l2', ascending=False).reset_index()\n",
    "top_by_both = top_by_both.rename(columns={\"index\": \"feature\"})\n",
    "pl_df = pl.from_pandas(top_by_both)\n",
    "\n",
    "print(\"Top by both (L2):\\n\")\n",
    "print(pl_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865e7ff",
   "metadata": {},
   "source": [
    "Many feature–target relations in the scatter plots look non-linear, so Pearson (linear) correlation can miss signal. Alternatives:\n",
    "- Spearman's rho: rank-based; captures monotonic but non-linear relationships.\n",
    "- Kendall's tau: rank-based; more robust to outliers but slower on large data.\n",
    "- Mutual information (MI): model-free dependency measure; captures arbitrary non-linear relations (non-negative).\n",
    "\n",
    "Below, compute Spearman, Kendall, and MI for each feature vs `Y1` and `Y2`, then rank features by these scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_corr_series(X_col, y, method):\n",
    "    m = X_col.notna() & y.notna()\n",
    "    if m.sum() < 3:\n",
    "        return np.nan\n",
    "    if method == 'spearman':\n",
    "        rho, _ = spearmanr(X_col[m], y[m])\n",
    "        return rho\n",
    "    elif method == 'kendall':\n",
    "        tau, _ = kendalltau(X_col[m], y[m])\n",
    "        return tau\n",
    "    else:\n",
    "        raise ValueError('method must be spearman or kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1fb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRELATIONS WITH RANKING\n",
      "shape: (18, 12)\n",
      "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ feature ┆ spearman_Y ┆ spearman_ ┆ kendall_Y ┆ … ┆ rank_stre ┆ rank_MI_Y ┆ rank_MI_Y ┆ rank_over │\n",
      "│ ---     ┆ 1          ┆ Y2        ┆ 1         ┆   ┆ ngth_Y2   ┆ 1         ┆ 2         ┆ all       │\n",
      "│ str     ┆ ---        ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│         ┆ f64        ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
      "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ A       ┆ -0.002308  ┆ 0.609209  ┆ -0.00138  ┆ … ┆ 5.0       ┆ 14.0      ┆ 2.0       ┆ 9.75      │\n",
      "│ B       ┆ -0.021435  ┆ 0.62362   ┆ -0.013819 ┆ … ┆ 3.0       ┆ 12.0      ┆ 4.0       ┆ 8.25      │\n",
      "│ C       ┆ 0.695609   ┆ -0.00963  ┆ 0.522716  ┆ … ┆ 17.0      ┆ 5.0       ┆ 12.0      ┆ 10.0      │\n",
      "│ D       ┆ -0.016948  ┆ 0.612065  ┆ -0.011279 ┆ … ┆ 4.0       ┆ 10.0      ┆ 5.0       ┆ 8.75      │\n",
      "│ E       ┆ 0.70126    ┆ -0.016222 ┆ 0.52591   ┆ … ┆ 11.0      ┆ 6.0       ┆ 15.0      ┆ 9.25      │\n",
      "│ …       ┆ …          ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
      "│ N       ┆ 0.601728   ┆ -0.013582 ┆ 0.441339  ┆ … ┆ 14.0      ┆ 8.0       ┆ 16.0      ┆ 11.5      │\n",
      "│ O       ┆ 0.286263   ┆ 0.121285  ┆ 0.21202   ┆ … ┆ 9.0       ┆ 17.0      ┆ 17.0      ┆ 13.0      │\n",
      "│ P       ┆ 0.053446   ┆ 0.054063  ┆ 0.04364   ┆ … ┆ 10.0      ┆ 18.0      ┆ 18.0      ┆ 14.0      │\n",
      "│ Y1      ┆ 1.0        ┆ -0.008829 ┆ 1.0       ┆ … ┆ 18.0      ┆ 1.0       ┆ 6.0       ┆ 6.5       │\n",
      "│ Y2      ┆ -0.008829  ┆ 1.0       ┆ -0.00554  ┆ … ┆ 1.0       ┆ 9.0       ┆ 1.0       ┆ 7.0       │\n",
      "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "\n",
      "Top Spearman (Y1):\n",
      "\n",
      "shape: (18, 2)\n",
      "┌─────────┬─────────────┐\n",
      "│ feature ┆ spearman_Y1 │\n",
      "│ ---     ┆ ---         │\n",
      "│ str     ┆ f64         │\n",
      "╞═════════╪═════════════╡\n",
      "│ Y1      ┆ 1.0         │\n",
      "│ G       ┆ 0.799796    │\n",
      "│ M       ┆ 0.712658    │\n",
      "│ J       ┆ 0.709836    │\n",
      "│ E       ┆ 0.70126     │\n",
      "│ …       ┆ …           │\n",
      "│ B       ┆ -0.021435   │\n",
      "│ F       ┆ -0.017817   │\n",
      "│ D       ┆ -0.016948   │\n",
      "│ Y2      ┆ -0.008829   │\n",
      "│ A       ┆ -0.002308   │\n",
      "└─────────┴─────────────┘\n",
      "\n",
      "Top Spearman (Y2):\n",
      "\n",
      "shape: (18, 2)\n",
      "┌─────────┬─────────────┐\n",
      "│ feature ┆ spearman_Y2 │\n",
      "│ ---     ┆ ---         │\n",
      "│ str     ┆ f64         │\n",
      "╞═════════╪═════════════╡\n",
      "│ Y2      ┆ 1.0         │\n",
      "│ K       ┆ 0.626156    │\n",
      "│ B       ┆ 0.62362     │\n",
      "│ D       ┆ 0.612065    │\n",
      "│ A       ┆ 0.609209    │\n",
      "│ …       ┆ …           │\n",
      "│ N       ┆ -0.013582   │\n",
      "│ J       ┆ -0.013284   │\n",
      "│ H       ┆ -0.011421   │\n",
      "│ C       ┆ -0.00963    │\n",
      "│ Y1      ┆ -0.008829   │\n",
      "└─────────┴─────────────┘\n",
      "\n",
      "Top Mutual Information (Y1):\n",
      "\n",
      "shape: (18, 2)\n",
      "┌─────────┬─────────────┐\n",
      "│ feature ┆ spearman_Y1 │\n",
      "│ ---     ┆ ---         │\n",
      "│ str     ┆ f64         │\n",
      "╞═════════╪═════════════╡\n",
      "│ Y1      ┆ 1.0         │\n",
      "│ G       ┆ 0.799796    │\n",
      "│ M       ┆ 0.712658    │\n",
      "│ J       ┆ 0.709836    │\n",
      "│ C       ┆ 0.695609    │\n",
      "│ …       ┆ …           │\n",
      "│ A       ┆ -0.002308   │\n",
      "│ I       ┆ -0.032693   │\n",
      "│ F       ┆ -0.017817   │\n",
      "│ O       ┆ 0.286263    │\n",
      "│ P       ┆ 0.053446    │\n",
      "└─────────┴─────────────┘\n",
      "\n",
      "Top Mutual Information (Y2):\n",
      "\n",
      "shape: (18, 2)\n",
      "┌─────────┬─────────────┐\n",
      "│ feature ┆ spearman_Y2 │\n",
      "│ ---     ┆ ---         │\n",
      "│ str     ┆ f64         │\n",
      "╞═════════╪═════════════╡\n",
      "│ Y2      ┆ 1.0         │\n",
      "│ A       ┆ 0.609209    │\n",
      "│ K       ┆ 0.626156    │\n",
      "│ B       ┆ 0.62362     │\n",
      "│ D       ┆ 0.612065    │\n",
      "│ …       ┆ …           │\n",
      "│ M       ┆ -0.015423   │\n",
      "│ E       ┆ -0.016222   │\n",
      "│ N       ┆ -0.013582   │\n",
      "│ O       ┆ 0.121285    │\n",
      "│ P       ┆ 0.054063    │\n",
      "└─────────┴─────────────┘\n",
      "\n",
      "Top Overall (avg rank of Spearman & MI for Y1 and Y2):\n",
      "\n",
      "shape: (18, 3)\n",
      "┌─────────┬─────────────┬─────────────┐\n",
      "│ feature ┆ spearman_Y1 ┆ spearman_Y2 │\n",
      "│ ---     ┆ ---         ┆ ---         │\n",
      "│ str     ┆ f64         ┆ f64         │\n",
      "╞═════════╪═════════════╪═════════════╡\n",
      "│ Y1      ┆ 1.0         ┆ -0.008829   │\n",
      "│ G       ┆ 0.799796    ┆ -0.013841   │\n",
      "│ Y2      ┆ -0.008829   ┆ 1.0         │\n",
      "│ K       ┆ -0.024321   ┆ 0.626156    │\n",
      "│ M       ┆ 0.712658    ┆ -0.015423   │\n",
      "│ …       ┆ …           ┆ …           │\n",
      "│ H       ┆ 0.688736    ┆ -0.011421   │\n",
      "│ N       ┆ 0.601728    ┆ -0.013582   │\n",
      "│ F       ┆ -0.017817   ┆ 0.55254     │\n",
      "│ O       ┆ 0.286263    ┆ 0.121285    │\n",
      "│ P       ┆ 0.053446    ┆ 0.054063    │\n",
      "└─────────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [c for c in train_data.columns if c not in ['time']]\n",
    "X = merged_data[feature_cols]\n",
    "y1 = merged_data['Y1']\n",
    "y2 = merged_data['Y2']\n",
    "\n",
    "spearman_y1 = {c: rank_corr_series(X[c], y1, 'spearman') for c in feature_cols}\n",
    "spearman_y2 = {c: rank_corr_series(X[c], y2, 'spearman') for c in feature_cols}\n",
    "kendall_y1 = {c: rank_corr_series(X[c], y1, 'kendall') for c in feature_cols}\n",
    "kendall_y2 = {c: rank_corr_series(X[c], y2, 'kendall') for c in feature_cols}\n",
    "\n",
    "X_num = X.select_dtypes(include=['number']).copy()\n",
    "\n",
    "X_num = X_num.fillna(X_num.median(numeric_only=True))\n",
    "y1_filled = y1.fillna(y1.median())\n",
    "y2_filled = y2.fillna(y2.median())\n",
    "\n",
    "mi_y1 = mutual_info_regression(X_num.values, y1_filled.values, random_state=0)\n",
    "mi_y2 = mutual_info_regression(X_num.values, y2_filled.values, random_state=0)\n",
    "mi_y1 = pd.Series(mi_y1, index=X_num.columns)\n",
    "mi_y2 = pd.Series(mi_y2, index=X_num.columns)\n",
    "\n",
    "nl_df = pd.DataFrame({\n",
    "    'spearman_Y1': pd.Series(spearman_y1),\n",
    "    'spearman_Y2': pd.Series(spearman_y2),\n",
    "    'kendall_Y1': pd.Series(kendall_y1),\n",
    "    'kendall_Y2': pd.Series(kendall_y2),\n",
    "}).fillna(0.0)\n",
    "\n",
    "nl_df['MI_Y1'] = 0.0\n",
    "nl_df['MI_Y2'] = 0.0\n",
    "for col in X_num.columns:\n",
    "    nl_df.loc[col, 'MI_Y1'] = mi_y1[col]\n",
    "    nl_df.loc[col, 'MI_Y2'] = mi_y2[col]\n",
    "\n",
    "nl_df['rank_strength_Y1'] = nl_df['spearman_Y1'].abs().rank(ascending=False, method='average')\n",
    "nl_df['rank_strength_Y2'] = nl_df['spearman_Y2'].abs().rank(ascending=False, method='average')\n",
    "nl_df['rank_MI_Y1'] = nl_df['MI_Y1'].rank(ascending=False, method='average')\n",
    "nl_df['rank_MI_Y2'] = nl_df['MI_Y2'].rank(ascending=False, method='average')\n",
    "nl_df['rank_overall'] = (nl_df['rank_strength_Y1'] + nl_df['rank_MI_Y1'] + nl_df['rank_strength_Y2'] + nl_df['rank_MI_Y2']) / 4.0\n",
    "nl_df_reset = nl_df.reset_index()\n",
    "nl_df_reset = nl_df_reset.rename(columns={\"index\": \"feature\"})\n",
    "nl_pl = pl.from_pandas(nl_df_reset)\n",
    "print(\"CORRELATIONS WITH RANKING\")\n",
    "print(nl_pl)\n",
    "\n",
    "top_spearman_Y1 = pl.from_pandas(nl_df.sort_values('spearman_Y1', key=lambda s: s.abs(), ascending=False).head(20).reset_index().rename(columns={\"index\": \"feature\"}))\n",
    "top_spearman_Y2 =  pl.from_pandas(nl_df.sort_values('spearman_Y2', key=lambda s: s.abs(), ascending=False).head(20).reset_index().rename(columns={\"index\": \"feature\"}))\n",
    "top_mi_Y1 =  pl.from_pandas(nl_df.sort_values('MI_Y1', ascending=False).head(20).reset_index().rename(columns={\"index\": \"feature\"}))\n",
    "top_mi_Y2 =  pl.from_pandas(nl_df.sort_values('MI_Y2', ascending=False).head(20).reset_index().rename(columns={\"index\": \"feature\"}))\n",
    "top_overall =  pl.from_pandas(nl_df.sort_values('rank_overall').head(20).reset_index().rename(columns={\"index\": \"feature\"}))\n",
    "\n",
    "\n",
    "print('\\nTop Spearman (Y1):\\n')\n",
    "print(top_spearman_Y1[:,['feature','spearman_Y1']])\n",
    "print('\\nTop Spearman (Y2):\\n')\n",
    "print(top_spearman_Y2[:,['feature','spearman_Y2']])\n",
    "print('\\nTop Mutual Information (Y1):\\n')\n",
    "print(top_mi_Y1[:,['feature','spearman_Y1']])\n",
    "print('\\nTop Mutual Information (Y2):\\n')\n",
    "print(top_mi_Y2[:,['feature','spearman_Y2']])\n",
    "print('\\nTop Overall (avg rank of Spearman & MI for Y1 and Y2):\\n')\n",
    "print(top_overall[:,['feature','spearman_Y1','spearman_Y2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae746ab",
   "metadata": {},
   "source": [
    "### 4) Visualize Relationships among Explanatory Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132fa569",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['time'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m corr_matrix = \u001b[43mtrain_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mP\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mY1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mY2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.corr(method=\u001b[33m\"\u001b[39m\u001b[33mpearson\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m      3\u001b[39m sns.heatmap(corr_matrix, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cmap=\u001b[33m\"\u001b[39m\u001b[33mcoolwarm\u001b[39m\u001b[33m\"\u001b[39m, center=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mauro\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quant-challenge-2025-65fAVH14-py3.11\\Lib\\site-packages\\pandas\\core\\frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mauro\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quant-challenge-2025-65fAVH14-py3.11\\Lib\\site-packages\\pandas\\core\\generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mauro\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quant-challenge-2025-65fAVH14-py3.11\\Lib\\site-packages\\pandas\\core\\generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mauro\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quant-challenge-2025-65fAVH14-py3.11\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['time'] not found in axis\""
     ]
    }
   ],
   "source": [
    "corr_matrix = train_data.to_pandas().drop(columns=[\"O\",\"P\",\"Y1\", \"Y2\", \"time\"]).corr(method=\"pearson\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Matrix (Explanatory Variables)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce2f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-challenge-2025-65fAVH14-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
